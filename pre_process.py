import pandas as pd
import numpy as np
from typing import Tuple, Dict, Any

# ============================================================================
# PHáº¦N 1: CLEANING, OUTLIER FILTERING, VÃ€ IMPUTATION (ÄÃƒ Sá»¬A Lá»–I GROUP IMPUTATION VÃ€ Lá»ŒC TEST)
# ============================================================================
# ============================================================================
# HÃ€M 1: TIá»€N Xá»¬ LÃ CÆ  Báº¢N (ToÃ n bá»™ dataset - trÆ°á»›c khi chia train/test)
# ============================================================================

def basic_preprocessing(df):
    """
    Tiá»n xá»­ lÃ½ CÆ  Báº¢N - KHÃ”NG GÃ‚Y LEAKAGE
    - Loáº¡i bá» duplicates
    - Drop cá»™t dÆ° thá»«a
    - Ã‰p kiá»ƒu dá»¯ liá»‡u
    - Chuáº©n hÃ³a categorical cá»‘ Ä‘á»‹nh
    """
    print("="*80)
    print("ğŸ“¦ Báº®T Äáº¦U TIá»€N Xá»¬ LÃ CÆ  Báº¢N")
    print("="*80 + "\n")

    df = df.copy()

    # 1ï¸âƒ£ Loáº¡i bá» trÃ¹ng list_id
    if 'list_id' in df.columns:
        before = len(df)
        df = df.drop_duplicates(subset='list_id', keep='first')
        print(f"ğŸ§¹ Loáº¡i bá» {before - len(df)} báº£n ghi trÃ¹ng list_id\n")


    # 3ï¸âƒ£ Ã‰p kiá»ƒu sá»‘
    numeric_cols = ['width', 'length', 'rooms', 'size', 'price_million_per_m2', 'price']
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    print(f"ğŸ”¢ Ã‰p kiá»ƒu sá»‘ cho cÃ¡c cá»™t: {[c for c in numeric_cols if c in df.columns]}\n")


    # 4ï¸âƒ£ Chuáº©n hÃ³a is_main_street
    if 'is_main_street' in df.columns:
        df['is_main_street'] = df['is_main_street'].replace(
            {'True': 1, 'False': 0, True: 1, False: 0, '': np.nan}
        ).astype('float')
        print("âœ… Chuáº©n hÃ³a is_main_street thÃ nh 0/1\n")


    # 5ï¸âƒ£ Xá»­ lÃ½ legal_doc_text
    if 'legal_doc_text' in df.columns:
        df['legal_doc_text'] = df['legal_doc_text'].fillna('KhÃ´ng rÃµ')

        mapping = {
            "KhÃ´ng rÃµ": "Thiáº¿u/KhÃ´ng rÃµ",
            "KhÃ¡c": "Thiáº¿u/KhÃ´ng rÃµ",
            "Giáº¥y tay / ChÆ°a cÃ³ sá»•": "Giáº¥y tay/ChÆ°a cÃ³ sá»•",
            "Há»£p Ä‘á»“ng mua bÃ¡n": "Há»£p Ä‘á»“ng mua bÃ¡n",
            "Äang chá» sá»•": "Äang chá» sá»•",
            "Sá»• há»“ng / Sá»• Ä‘á» Ä‘áº§y Ä‘á»§": "Sá»• há»“ng / Sá»• Ä‘á» Ä‘áº§y Ä‘á»§"
        }
        df['legal_doc_text'] = df['legal_doc_text'].replace(mapping)

        ordinal_map = {
            "Thiáº¿u/KhÃ´ng rÃµ": 0,
            "Giáº¥y tay/ChÆ°a cÃ³ sá»•": 1,
            "Há»£p Ä‘á»“ng mua bÃ¡n": 2,
            "Äang chá» sá»•": 3,
            "Sá»• há»“ng / Sá»• Ä‘á» Ä‘áº§y Ä‘á»§": 4
        }
        df['legal_doc_encoded'] = df['legal_doc_text'].map(ordinal_map)
        print("âœ… Encode legal_doc_text\n")

    print(f"ğŸ“¦ KÃ­ch thÆ°á»›c sau tiá»n xá»­ lÃ½: {df.shape}")
    print("="*80 + "\n")

    return df

def initial_cleaning_single(
    df: pd.DataFrame,
    target_name: str = 'price',
    category_col: str = 'category_name'
) -> pd.DataFrame:
    """
    Version Ä‘Æ¡n giáº£n cho prediction - chá»‰ nháº­n vÃ o má»™t DataFrame
    """
    df = df.copy()
    
    # KhÃ´ng lá»c outliers cho prediction
    # Chá»‰ Ã¡p dá»¥ng cÃ¡c bÆ°á»›c cleaning cÆ¡ báº£n
    
    # Äáº£m báº£o cÃ¡c kiá»ƒu dá»¯ liá»‡u Ä‘Ãºng
    if 'rooms' in df.columns:
        df['rooms'] = pd.to_numeric(df['rooms'], errors='coerce')
    
    # Fill NA values
    df = df.fillna({
        'direction_text': 'KhÃ´ng cÃ³ thÃ´ng tin',
        'legal_doc_text': 'KhÃ´ng cÃ³ thÃ´ng tin',
        'region_name': 'KhÃ´ng cÃ³ thÃ´ng tin',
        'area_name': 'KhÃ´ng cÃ³ thÃ´ng tin',
        'ward_name': 'KhÃ´ng cÃ³ thÃ´ng tin'
    })
    
    return df

def initial_cleaning_and_outlier_filtering(
    X_train: pd.DataFrame,
    X_test: pd.DataFrame,
    y_train: pd.Series,
    y_test: pd.Series,
    target_name: str = 'price',
    category_col: str = 'category_name'
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, Dict[str, Any]]:

    # Báº¯t buá»™c: Copy vÃ  Reset Index ban Ä‘áº§u Ä‘á»ƒ Ä‘áº£m báº£o cÃ¡c Series/DataFrame khá»›p nhau.
    X_train = X_train.copy()
    X_test = X_test.copy()
    y_train = y_train.copy()
    y_test = y_test.copy()

    artifacts = {}
    print("="*80)
    print("ğŸ§¹ CLEANING & OUTLIER FILTERING (BY CATEGORY)")
    print("="*80 + "\n")

    # ----------------------------------------
    # BÆ¯á»šC 0: TIá»€N Xá»¬ LÃ CHUáº¨N Bá»Š (Lá»c cá»™t category náº¿u khÃ´ng cÃ³)
    # ----------------------------------------
    use_category = category_col in X_train.columns
    if not use_category:
        print(f"âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng tÃ¬m tháº¥y cá»™t '{category_col}'. Xá»­ lÃ½ outliers trÃªn toÃ n bá»™ dá»¯ liá»‡u.")

    # ----------------------------------------
    # BÆ¯á»šC 1: Xá»¬ LÃ OUTLIERS (THEO CATEGORY HOáº¶C TOÃ€N Bá»˜)
    # ----------------------------------------
    print("ğŸ“Œ BÆ¯á»šC 1: Lá»c Outliers")
    print("-" * 40)

    outlier_cols = ['size', 'price_million_per_m2', 'width', 'length', 'rooms']

    def get_outlier_bounds(series):
        Q1, Q3 = series.quantile(0.25), series.quantile(0.75)
        IQR = Q3 - Q1
        return Q1 - 1.5 * IQR, Q3 + 1.5 * IQR

    category_outlier_bounds = {}


    # Khá»Ÿi táº¡o mask toÃ n cá»¥c cho Train vÃ  Test (dÃ¹ng index Ä‘á»ƒ Ã¡p dá»¥ng)
    train_indices = X_train.index.copy()
    test_indices = X_test.index.copy()

    # 1.1 Lá»c Outlier Target (Price)
    # TÃ­nh ngÆ°á»¡ng trÃªn táº­p Train ban Ä‘áº§u
    lower_y, upper_y = get_outlier_bounds(y_train)

    # Lá»c Train
    mask_y_train = (y_train >= lower_y) & (y_train <= upper_y)
    train_indices = train_indices[mask_y_train]

    # Lá»c Test
    mask_y_test = (y_test.reindex(X_test.index) >= lower_y) & (y_test.reindex(X_test.index) <= upper_y) # Reindex an toÃ n
    test_indices = test_indices[mask_y_test]

    artifacts['target_outlier_bounds'] = {'lower': lower_y, 'upper': upper_y}
    print(f"   Lá»c Outlier (Price): Loáº¡i {len(X_train) - len(train_indices)} (Train) | Loáº¡i {len(X_test) - len(test_indices)} (Test)")


    # 1.2 Lá»c Outliers tá»« FEATURES (TÆ°Æ¡ng tá»±, dÃ¹ng ngÆ°á»¡ng chung tá»« Train)
    feature_outlier_bounds = {}

    if use_category:
        # Náº¿u dÃ¹ng category, cáº§n tÃ­nh bounds cho má»—i category vÃ  Ã¡p dá»¥ng cho cáº£ X/Y
        # Logic nÃ y quÃ¡ phá»©c táº¡p vÃ  dá»… lá»—i. Äá» xuáº¥t DÃ¹ng Outlier Capping (giá»›i háº¡n) thay vÃ¬ Lá»c
        # Táº¡m thá»i, ta dÃ¹ng logic lá»c toÃ n bá»™ Ä‘Æ¡n giáº£n (fallback) Ä‘á»ƒ giá»¯ cho hÃ m nÃ y lÃ  bÆ°á»›c lá»c.
        categories = X_train[category_col].unique()

        # NOTE: Äá»‘i vá»›i Outlier theo nhÃ³m, nÃªn dÃ¹ng CAPPING (giá»›i háº¡n giÃ¡ trá»‹) trong Pipeline
        # thay vÃ¬ Filtering, vÃ¬ Filtering theo nhÃ³m ráº¥t dá»… lá»—i vÃ  lÃ m máº¥t dá»¯ liá»‡u.
        # á» Ä‘Ã¢y, ta chá»‰ lá»c chung theo ngÆ°á»¡ng sau khi price Ä‘Ã£ lá»c.

    for col in outlier_cols:
        if col in X_train.columns and X_train.loc[train_indices, col].notna().sum() > 0:
            # TÃ­nh ngÆ°á»¡ng trÃªn táº­p Train Ä‘Ã£ lá»c Outlier Price
            lower, upper = get_outlier_bounds(X_train.loc[train_indices, col].dropna())
            feature_outlier_bounds[col] = {'lower': lower, 'upper': upper}

            # Lá»c Train
            mask_train = ((X_train[col] >= lower) & (X_train[col] <= upper)) | X_train[col].isna()
            train_indices = train_indices[mask_train.loc[train_indices]]

            # Lá»c Test
            mask_test = ((X_test[col] >= lower) & (X_test[col] <= upper)) | X_test[col].isna()
            test_indices = test_indices[mask_test.loc[test_indices]]

            print(f"   Lá»c Outlier ({col}): Train size cÃ²n {len(train_indices)} | Test size cÃ²n {len(test_indices)}")

    artifacts['feature_outlier_bounds'] = feature_outlier_bounds

    # ÃP Dá»¤NG Lá»ŒC CUá»I CÃ™NG
    X_train = X_train.loc[train_indices]
    y_train = y_train.loc[train_indices]
    X_test = X_test.loc[test_indices]
    y_test = y_test.loc[test_indices]

    print(f"\nâœ… Train size cuá»‘i sau lá»c: {X_train.shape}")
    print(f"âœ… Test size cuá»‘i sau lá»c: {X_test.shape}\n")

    # ----------------------------------------
    # BÆ¯á»šC 2: Xá»¬ LÃ MISSING VALUES (Imputation)
    # ----------------------------------------
    print("="*80)
    print("ğŸ“Œ BÆ¯á»šC 2: Xá»­ lÃ½ Missing Values (Imputation)")
    print("="*80 + "\n")

    train_missing_before = X_train.isna().sum().sum()

    if train_missing_before > 0 or X_test.isna().sum().sum() > 0:
        fill_values = {}

        # 2.1 is_main_street (Fill báº±ng 0/False)
        if 'is_main_street' in X_train.columns:
            fill_val = 0.0
            X_train.loc[:, 'is_main_street'] = X_train['is_main_street'].fillna(fill_val)
            X_test.loc[:, 'is_main_street'] = X_test['is_main_street'].fillna(fill_val)
            fill_values['is_main_street'] = fill_val
            print("âœ… Filled 'is_main_street' with 0.0\n")

        # 2.2 width, length, rooms theo Group Mean/Overall Mean
        fill_cols = ['width', 'length', 'rooms']
        group_cols = ['region_name', 'area_name']
        available_groups = [c for c in X_train.columns if c in group_cols]

        if available_groups:
            print(f"ğŸ”„ Group Imputation theo: {available_groups}")

        for col in fill_cols:
            if col in X_train.columns:
                missing_train = X_train[col].isna().sum()
                missing_test = X_test[col].isna().sum()

                if missing_train == 0 and missing_test == 0:
                    continue

                # TÃ­nh Overall Mean Tá»ª TRAIN
                overall_mean = X_train[col].mean()

                if available_groups and not np.isnan(overall_mean):
                    # TÃ­nh group means Tá»ª TRAIN (bá» qua NaN Ä‘á»ƒ tÃ­nh mean Ä‘Ãºng)
                    train_group_means = X_train.groupby(available_groups)[col].mean()
                    train_group_means_dict = train_group_means.to_dict()

                    # HÃ m Ä‘iá»n khuyáº¿t
                    def group_imputer(row):
                        if pd.isna(row[col]):
                            key = tuple(row[g] for g in available_groups)
                            # Sá»­ dá»¥ng group mean. Náº¿u group mean lÃ  NaN, fallback vá» Overall Mean
                            group_val = train_group_means_dict.get(key, overall_mean)
                            return group_val if not np.isnan(group_val) else overall_mean
                        return row[col]

                    # Ãp dá»¥ng cho TRAIN vÃ  TEST
                    X_train.loc[:, col] = X_train.apply(group_imputer, axis=1)
                    X_test.loc[:, col] = X_test.apply(group_imputer, axis=1)

                # BÆ¯á»šC CUá»I: FILL Báº¤T Ká»² NaN CÃ’N Láº I Báº°NG OVERALL MEAN (sau group imputation)
                X_train.loc[:, col] = X_train[col].fillna(overall_mean)
                X_test.loc[:, col] = X_test[col].fillna(overall_mean)

                fill_values[col] = overall_mean
                print(f" Â âœ… {col}: Filled {missing_train} (train) + {missing_test} (test) | Final Mean: {overall_mean:.2f}")

        # 2.3 CÃ¡c cá»™t sá»‘ khÃ¡c (Median)
        numeric_cols_rest = [c for c in X_train.select_dtypes(include=['float64', 'int64']).columns if c not in fill_cols and c != 'is_main_street']

        if numeric_cols_rest:
            print(f"\nğŸ”¢ Median Imputation cho cÃ¡c cá»™t cÃ²n láº¡i:")

        for col in numeric_cols_rest:
            missing_train = X_train[col].isna().sum()
            if missing_train > 0 or X_test[col].isna().sum() > 0:
                median_val = X_train[col].median()
                X_train.loc[:, col] = X_train[col].fillna(median_val)
                X_test.loc[:, col] = X_test[col].fillna(median_val)
                fill_values[col] = median_val
                print(f" Â âœ… {col}: Filled {missing_train} (train) | Median: {median_val:.2f}")

        # 2.4 Categorical (Mode)
        cat_cols = X_train.select_dtypes(include=['object', 'category']).columns

        if len(cat_cols) > 0:
            print(f"\nğŸ“‹ Mode Imputation cho categorical:")

        for col in cat_cols:
            missing_train = X_train[col].isna().sum()
            if missing_train > 0 or X_test[col].isna().sum() > 0:
                mode_val = X_train[col].mode()[0] if len(X_train[col].mode()) > 0 else 'Unknown'
                X_train.loc[:, col] = X_train[col].fillna(mode_val)
                X_test.loc[:, col] = X_test[col].fillna(mode_val)
                fill_values[col] = mode_val
                print(f" Â âœ… {col}: Filled {missing_train} (train) | Mode: {mode_val}")

        artifacts['fill_values'] = fill_values

    # ----------------------------------------
    # KIá»‚M TRA CUá»I CÃ™NG
    # ----------------------------------------
    train_missing_after = X_train.isna().sum().sum()
    test_missing_after = X_test.isna().sum().sum()

    print(f"\n{'='*80}")
    print("âœ… Tá»”NG Káº¾T")
    print(f"{'='*80}")
    print(f"Missing sau imputation:")
    print(f" Â Train: {train_missing_after} (PhaÌ‰i laÌ€ 0)")
    print(f" Â Test: {test_missing_after} (PhaÌ‰i laÌ€ 0)")

    if train_missing_after > 0 or test_missing_after > 0:
        print("\nâš ï¸ VáºªN CÃ’N MISSING VALUES SAU IMPUTATION! Cáº§n kiá»ƒm tra láº¡i cÃ¡c cá»™t.")

    print(f"\nKÃ­ch thÆ°á»›c cuá»‘i:")
    print(f" Â Train: {X_train.shape}")
    print(f" Â Test: {X_test.shape}")
    print(f"\nArtifacts: {list(artifacts.keys())}\n")

    return X_train, X_test, y_train, y_test, artifacts